-----------------------Date: 2021/04/29 13:22:16-----------------------
[epoch:   1/100, ite: 335] train loss: 1.440983, tar: 0.165312 
[epoch:   2/100, ite: 335] train loss: 0.638331, tar: 0.077005 
[epoch:   3/100, ite: 335] train loss: 0.399464, tar: 0.048228 
[epoch:   4/100, ite: 335] train loss: 0.329992, tar: 0.040271 
[epoch:   5/100, ite: 335] train loss: 0.322667, tar: 0.039639 
[epoch:   6/100, ite: 335] train loss: 0.291786, tar: 0.035379 
[epoch:   7/100, ite: 335] train loss: 0.314623, tar: 0.038470 
[epoch:   8/100, ite: 335] train loss: 0.451499, tar: 0.056933 
[epoch:   9/100, ite: 335] train loss: 0.263772, tar: 0.032199 
[epoch:  10/100, ite: 335] train loss: 0.261513, tar: 0.032679 
[epoch:  11/100, ite: 335] train loss: 0.263797, tar: 0.032783 
[epoch:  12/100, ite: 335] train loss: 0.248949, tar: 0.030368 
[epoch:  13/100, ite: 335] train loss: 0.230831, tar: 0.028330 
[epoch:  14/100, ite: 335] train loss: 0.237964, tar: 0.029284 
[epoch:  15/100, ite: 335] train loss: 0.228743, tar: 0.028054 
[epoch:  16/100, ite: 335] train loss: 0.223669, tar: 0.027385 
[epoch:  17/100, ite: 335] train loss: 0.225904, tar: 0.027559 
[epoch:  18/100, ite: 335] train loss: 0.211037, tar: 0.025870 
[epoch:  19/100, ite: 335] train loss: 0.212611, tar: 0.026270 
[epoch:  20/100, ite: 335] train loss: 0.213756, tar: 0.026412 
[epoch:  21/100, ite: 335] train loss: 0.212190, tar: 0.026265 
[epoch:  22/100, ite: 335] train loss: 0.254473, tar: 0.032050 
[epoch:  23/100, ite: 335] train loss: 0.207893, tar: 0.025827 
[epoch:  24/100, ite: 335] train loss: 0.203604, tar: 0.025108 
[epoch:  25/100, ite: 335] train loss: 0.200920, tar: 0.024785 
[epoch:  26/100, ite: 335] train loss: 0.200609, tar: 0.024790 
[epoch:  27/100, ite: 335] train loss: 0.198251, tar: 0.024495 
[epoch:  28/100, ite: 335] train loss: 0.203045, tar: 0.025323 
[epoch:  29/100, ite: 335] train loss: 0.199210, tar: 0.024623 
[epoch:  30/100, ite: 335] train loss: 0.199346, tar: 0.024652 
[epoch:  31/100, ite: 335] train loss: 0.198563, tar: 0.024650 
[epoch:  32/100, ite: 335] train loss: 0.197885, tar: 0.024508 
[epoch:  33/100, ite: 335] train loss: 0.195831, tar: 0.024176 
[epoch:  34/100, ite: 335] train loss: 0.195289, tar: 0.024135 
[epoch:  35/100, ite: 335] train loss: 0.193849, tar: 0.024006 
[epoch:  36/100, ite: 335] train loss: 0.195818, tar: 0.024364 
[epoch:  37/100, ite: 335] train loss: 0.194775, tar: 0.024133 
[epoch:  38/100, ite: 335] train loss: 0.200012, tar: 0.024916 
[epoch:  39/100, ite: 335] train loss: 0.193344, tar: 0.024116 
[epoch:  40/100, ite: 335] train loss: 0.196338, tar: 0.024587 
[epoch:  41/100, ite: 335] train loss: 0.195285, tar: 0.024355 
[epoch:  42/100, ite: 335] train loss: 0.191552, tar: 0.023757 
[epoch:  43/100, ite: 335] train loss: 0.192571, tar: 0.023893 
[epoch:  44/100, ite: 335] train loss: 0.194458, tar: 0.024201 
[epoch:  45/100, ite: 335] train loss: 0.193097, tar: 0.024017 
[epoch:  46/100, ite: 335] train loss: 0.193065, tar: 0.024049 
[epoch:  47/100, ite: 335] train loss: 0.194904, tar: 0.024307 
[epoch:  48/100, ite: 335] train loss: 0.195270, tar: 0.024336 
[epoch:  49/100, ite: 335] train loss: 0.193012, tar: 0.024159 
[epoch:  50/100, ite: 335] train loss: 0.194099, tar: 0.024279 
[epoch:  51/100, ite: 335] train loss: 0.196569, tar: 0.024544 
[epoch:  52/100, ite: 335] train loss: 0.191132, tar: 0.023761 
[epoch:  53/100, ite: 335] train loss: 0.193157, tar: 0.024167 
[epoch:  54/100, ite: 335] train loss: 0.192514, tar: 0.024032 
[epoch:  55/100, ite: 335] train loss: 0.193087, tar: 0.024019 
[epoch:  56/100, ite: 335] train loss: 0.192074, tar: 0.023892 
[epoch:  57/100, ite: 335] train loss: 0.193165, tar: 0.024131 
[epoch:  58/100, ite: 335] train loss: 0.194376, tar: 0.024201 
[epoch:  59/100, ite: 335] train loss: 0.191892, tar: 0.023929 
[epoch:  60/100, ite: 335] train loss: 0.192468, tar: 0.023925 
[epoch:  61/100, ite: 335] train loss: 0.193065, tar: 0.024064 
